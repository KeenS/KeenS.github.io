<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Druid on κeenのHappy Hacκing Blog</title>
    <link>/categories/druid/index.xml</link>
    <description>Recent content in Druid on κeenのHappy Hacκing Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja-jp</language>
    <atom:link href="/categories/druid/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>druidというリアルタイムデータ分析ツールを知った</title>
      <link>/blog/2016/02/27/druidtoiuriarutaimude_tabunsekitsu_ruwoshitta</link>
      <pubDate>Sat, 27 Feb 2016 21:28:16 +0900</pubDate>
      
      <guid>/blog/2016/02/27/druidtoiuriarutaimude_tabunsekitsu_ruwoshitta</guid>
      <description>&lt;p&gt;κeenです。社内ハッカソンに出てきた。そこでdruidというツール（？）を触ったのでそれについて。

読み方は「ドゥルイド」でいいのかな？公式ページは&lt;a href=&#34;http://druid.io/&#34;&gt;こちら&lt;/a&gt;。&lt;a href=&#34;https://metamarkets.com/&#34;&gt;Metamarkets&lt;/a&gt;が主導で開発しているようで、&lt;a href=&#34;https://github.com/druid-io/druid&#34;&gt;オープンソースになっている&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;公式サイトを少し回遊してもらうと分かると思うが、時系列データを分散環境でストリーミング処理出来るツール。分散環境で動くだけあってコンポーネントはいくつかある。&lt;/p&gt;

&lt;p&gt;主にはストリーミングデータを取り込む「REALTIME」、クライアントからのクエリを処理する「BROKER」、過去のデータを処理する「HISTORICAL」があるようだ。
BROKERがDEEP STORAGE(s3などの永続データストア)にデータを保存し、HISTORICALがオンデマンドにそのデータを読み出してBROKERに返す。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://druid.io/docs/img/druid-dataflow-3.png&#34; alt=&#34;design of druid&#34; /&gt;&lt;/p&gt;

&lt;p&gt;イメージとしてはこんな感じだが、実際に動かすのには他のコンポーネントも必要で、分散環境に必須なZookeeperが必要なのはもちろんのこと、全体を司る「COORDINATOR」、取り込んだデータのメタデータを保存する「METADATA STORAGE」も必要になる。&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://druid.io/docs/img/druid-manage-1.png&#34; alt=&#34;detailed design of druid&#34; /&gt;&lt;/p&gt;

&lt;p&gt;画像の出展は&lt;a href=&#34;http://druid.io/docs/0.8.3/design/design.html&#34;&gt;こちら&lt;/a&gt;。&lt;/p&gt;

&lt;p&gt;中々に大仰なアーキテクチャだがどのみちリアルタイムデータ分析基盤を作ろうと思うとこれくらい必要になる。それを1まとめにしてディストリビュートしてくれるdruidを使った方がなんぼか近道な気はする。&lt;/p&gt;

&lt;p&gt;さて、これを1インスタンスで動かそうと思うと、DEEP STORAGEはローカルファイルシステム、METADATA STORAGEは組込みのDerby DBでまかなえ、REALTIMEはデータを取り込む時にのみ必要なのでZookeeper、Coordinator、Broker、Historical、都合4つのJava製ミドルウェアを起動すればどうにか使える。
これら合わせても2GBくらいのメモリしか必要なかったので十分手元で動く。&lt;/p&gt;

&lt;p&gt;さて、このDruid、どういうことが出来るかというとクエリに注目すれば「Group By付きのAggrigation Functionを高速に動かす」が主な目的だろうか。&lt;a href=&#34;http://druid.io/docs/0.8.3/querying/querying.html&#34;&gt;他にも色々ある&lt;/a&gt;が。
BIツールや他のダッシュボードツールなんかと連携してストリーミングデータをリアルタイムに可視化するのに一役買う。YahooやAlibabaなんかでも&lt;a href=&#34;http://druid.io/community/&#34;&gt;使われているようだ&lt;/a&gt;。
例えばDruidをサポートするダッシュボードツール、&lt;a href=&#34;https://github.com/mistercrunch/panoramix&#34;&gt;panoramix&lt;/a&gt;なんかもある。&lt;/p&gt;

&lt;p&gt;今回のハッカソンはGCPがテーマで、Cloud Pub/Subからデータを取り込むことになったがDruidにはPub/Subからデータを取り込むREALTIMEがない。ということでハッカソンで&lt;a href=&#34;https://github.com/KeenS/druid/tree/pubsub-extension/extensions/cloud-pubsub&#34;&gt;Pub/Sub extensionを作った&lt;/a&gt;。
メーリスに投稿して様子を覘った上でコードを整理してプルリクを出す予定だ。
拡張は思ったよりも作りやすく、ドキュメントを読まなくても既存のKafka拡張を参考にするだけで書けた。まあ、その後苦労したが。&lt;/p&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34; data-lang=&#34;ja&#34;&gt;&lt;p lang=&#34;ja&#34; dir=&#34;ltr&#34;&gt;はじめて使うDBのプラグイン書いたらデータのロードは出来たもののクエリの投げ方が分からずに入ったデータを確認出来ない…っ…&lt;/p&gt;&amp;mdash; κeen (@blackenedgold) &lt;a href=&#34;https://twitter.com/blackenedgold/status/703202304913051648&#34;&gt;2016年2月26日&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&#34;//platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;今回作ったのはFirehose Pluginと呼ばれるものだが、他にもプラグインの種類は&lt;a href=&#34;http://druid.io/docs/0.8.3/development/modules.html&#34;&gt;色々ある&lt;/a&gt;みたいだ。
しかしFirehose Pluginの基底クラスはあまりストリーミングデータのインポートには良くない気がする。FirehoseV2というのがあって、それが良いインターフェースになっていたが使い方が分からなかった。&lt;/p&gt;

&lt;p&gt;今が0.9.0-SNAPSHOT。1.0.0が出る頃が楽しみだ。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>